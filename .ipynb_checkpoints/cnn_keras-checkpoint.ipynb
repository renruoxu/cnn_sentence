{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: Quadro K2000\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.optimizers import SGD, RMSprop\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils \n",
    "from gensim.models import Word2Vec\n",
    "import numpy as np\n",
    "import re\n",
    "from gensim.parsing import strip_multiple_whitespaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### return sentence matrix\n",
    "def get_img(tokens,max_len = 50):\n",
    "    img = []\n",
    "    for w in tokens:\n",
    "        try:\n",
    "            img.append(model[w])\n",
    "        except:\n",
    "            pass\n",
    "    if len(img) >= max_len:\n",
    "        img = img[:max_len]\n",
    "    elif len(img) > 0:\n",
    "        n = max_len - len(img)\n",
    "        img = np.vstack([img,np.zeros((n,300))])\n",
    "    else:\n",
    "        img = np.zeros((max_len,300))\n",
    "    return np.array(img)\n",
    "\n",
    "def preprocess(sentence):\n",
    "    return strip_multiple_whitespaces(re.sub(r'[\\W_]+', ' ', sentence)).split(' ')\n",
    "def process_output(labels):\n",
    "    return np_utils.to_categorical(labels, nb_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 51s, sys: 5.89 s, total: 1min 57s\n",
      "Wall time: 1min 57s\n"
     ]
    }
   ],
   "source": [
    "pos_file =\"data/rt-polarity.pos\"\n",
    "neg_file = \"data/rt-polarity.neg\"\n",
    "w2v_file = \"data/GoogleNews-vectors-negative300.bin\"\n",
    "pos_sentences = open(pos_file).readlines()\n",
    "neg_sentences = open(neg_file).readlines()\n",
    "%time model = Word2Vec.load_word2vec_format(w2v_file,binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10662, 50, 300) (10662,)\n"
     ]
    }
   ],
   "source": [
    "pos_tokens = [preprocess(s) for s in pos_sentences]\n",
    "labels = [1]*len(pos_tokens)\n",
    "neg_tokens = [preprocess(s) for s in neg_sentences]\n",
    "labels += [0]*len(neg_sentences)\n",
    "imgs= [get_img(t) for t in pos_tokens+neg_tokens]\n",
    "imgs = np.array(imgs)\n",
    "labels = np.array(labels)\n",
    "print imgs.shape, labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8529, 1, 50, 300) (8529, 2) (2133, 1, 50, 300) (2133, 2)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "#train_X,test_X,train_y,test_y = train_test_split(imgs.reshape((imgs.shape[0],-1)),labels,test_size=0.2)\n",
    "train_X,test_X,train_y,test_y = train_test_split(imgs.reshape((imgs.shape[0],1,imgs.shape[1],imgs.shape[2])),labels,test_size=0.2)\n",
    "train_y = process_output(train_y)\n",
    "test_y = process_output(test_y)\n",
    "print train_X.shape, train_y.shape, test_X.shape, test_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.41 s, sys: 503 ms, total: 9.91 s\n",
      "Wall time: 9.92 s\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Convolution2D(nb_filter = 32, stack_size = 1, nb_row = 3, nb_col = 3, \n",
    "                        border_mode=\"full\", activation=\"relu\"))\n",
    "model.add(Convolution2D(nb_filter = 32, stack_size = 32, nb_row = 3, nb_col = 3, \n",
    "                        activation=\"relu\"))\n",
    "model.add(MaxPooling2D(poolsize=(2, 2)))\n",
    "model.add(Dropout(.25))\n",
    "\n",
    "model.add(Flatten()) ## flatten to vectors - from convolution layer to vector layer\n",
    "## 28x28 image after (2, 2)-pooling becomes (14, 14)\n",
    "model.add(Dense(120000, 128, activation=\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(128, 2, activation=\"softmax\"))\n",
    "\n",
    "## compile with loss function and optimizer\n",
    "## benchmark the time to compile\n",
    "%time model.compile(loss = \"categorical_crossentropy\", optimizer = \"adadelta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6823 samples, validate on 1706 samples\n",
      "Epoch 0\n",
      "130s - loss: 0.6925 - acc: 0.5266 - val_loss: 0.6872 - val_acc: 0.5199\n",
      "Epoch 1\n",
      "131s - loss: 0.6673 - acc: 0.6110 - val_loss: 0.6505 - val_acc: 0.6213\n",
      "Epoch 2\n",
      "131s - loss: 0.6010 - acc: 0.6814 - val_loss: 0.5978 - val_acc: 0.6682\n",
      "Epoch 3\n",
      "132s - loss: 0.5530 - acc: 0.7201 - val_loss: 0.5539 - val_acc: 0.7157\n",
      "Epoch 4\n",
      "130s - loss: 0.5184 - acc: 0.7469 - val_loss: 0.5447 - val_acc: 0.7104\n",
      "Epoch 5\n",
      "130s - loss: 0.4808 - acc: 0.7689 - val_loss: 0.5635 - val_acc: 0.7034\n",
      "Epoch 6\n",
      "131s - loss: 0.4480 - acc: 0.7889 - val_loss: 0.7600 - val_acc: 0.6518\n",
      "Epoch 7\n",
      "130s - loss: 0.4039 - acc: 0.8216 - val_loss: 0.6137 - val_acc: 0.7128\n",
      "Epoch 8\n",
      "130s - loss: 0.3636 - acc: 0.8432 - val_loss: 0.6533 - val_acc: 0.7057\n",
      "Epoch 9\n",
      "130s - loss: 0.3088 - acc: 0.8681 - val_loss: 0.6725 - val_acc: 0.7192\n",
      "2133/2133 [==============================] - 8s     \n",
      "[0.61854644848380469, 0.73886544772620721]\n"
     ]
    }
   ],
   "source": [
    "## train the model\n",
    "model.fit(train_X, train_y, batch_size=30, nb_epoch=10, \n",
    "          validation_split=0.2, show_accuracy=True, verbose=2)\n",
    "print model.evaluate(test_X, test_y, show_accuracy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
