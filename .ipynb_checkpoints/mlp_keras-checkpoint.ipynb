{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: Quadro K2000\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD, RMSprop\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils \n",
    "from gensim.models import Word2Vec\n",
    "import numpy as np\n",
    "import re\n",
    "from gensim.parsing import strip_multiple_whitespaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### return sentence matrix\n",
    "def get_img(tokens,max_len = 50):\n",
    "    img = []\n",
    "    for w in tokens:\n",
    "        try:\n",
    "            img.append(model[w])\n",
    "        except:\n",
    "            pass\n",
    "    if len(img) >= max_len:\n",
    "        img = img[:max_len]\n",
    "    elif len(img) > 0:\n",
    "        n = max_len - len(img)\n",
    "        img = np.vstack([img,np.zeros((n,300))])\n",
    "    else:\n",
    "        img = np.zeros((max_len,300))\n",
    "    return np.array(img)\n",
    "\n",
    "def preprocess(sentence):\n",
    "    return strip_multiple_whitespaces(re.sub(r'[\\W_]+', ' ', sentence)).split(' ')\n",
    "def process_output(labels):\n",
    "    return np_utils.to_categorical(labels, nb_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pos_file =\"data/rt-polarity.pos\"\n",
    "neg_file = \"data/rt-polarity.neg\"\n",
    "w2v_file = \"data/GoogleNews-vectors-negative300.bin\"\n",
    "pos_sentences = open(pos_file).readlines()\n",
    "neg_sentences = open(neg_file).readlines()\n",
    "model = Word2Vec.load_word2vec_format(w2v_file,binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10662, 50, 300) (10662,)\n"
     ]
    }
   ],
   "source": [
    "pos_tokens = [preprocess(s) for s in pos_sentences]\n",
    "labels = [1]*len(pos_tokens)\n",
    "neg_tokens = [preprocess(s) for s in neg_sentences]\n",
    "labels += [0]*len(neg_sentences)\n",
    "imgs= [get_img(t) for t in pos_tokens+neg_tokens]\n",
    "imgs = np.array(imgs)\n",
    "labels = np.array(labels)\n",
    "print imgs.shape, labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8529, 15000) (8529, 2) (2133, 15000) (2133, 2)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "train_X,test_X,train_y,test_y = train_test_split(imgs.reshape((imgs.shape[0],-1)),labels,test_size=0.2)\n",
    "train_y = process_output(train_y)\n",
    "test_y = process_output(test_y)\n",
    "print train_X.shape, train_y.shape, test_X.shape, test_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.06 s, sys: 327 ms, total: 4.38 s\n",
      "Wall time: 4.57 s\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(50 * 300, 128, activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(128, 128, activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(128, 2, activation=\"softmax\"))\n",
    "rms = RMSprop()\n",
    "%time model.compile(loss = \"categorical_crossentropy\", optimizer = rms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5970 samples, validate on 2559 samples\n",
      "Epoch 0\n",
      "1s - loss: 0.6909 - acc: 0.5387 - val_loss: 0.6829 - val_acc: 0.6155\n",
      "Epoch 1\n",
      "1s - loss: 0.6631 - acc: 0.6487 - val_loss: 0.6330 - val_acc: 0.6702\n",
      "Epoch 2\n",
      "1s - loss: 0.5839 - acc: 0.7179 - val_loss: 0.5600 - val_acc: 0.7190\n",
      "Epoch 3\n",
      "1s - loss: 0.4976 - acc: 0.7618 - val_loss: 0.5519 - val_acc: 0.7093\n",
      "Epoch 4\n",
      "1s - loss: 0.4294 - acc: 0.8062 - val_loss: 0.6420 - val_acc: 0.6776\n",
      "Epoch 5\n",
      "1s - loss: 0.3671 - acc: 0.8392 - val_loss: 0.5577 - val_acc: 0.7308\n",
      "Epoch 6\n",
      "1s - loss: 0.3169 - acc: 0.8653 - val_loss: 0.6399 - val_acc: 0.7085\n",
      "Epoch 7\n",
      "1s - loss: 0.2814 - acc: 0.8873 - val_loss: 0.6716 - val_acc: 0.7046\n",
      "Epoch 8\n",
      "1s - loss: 0.2444 - acc: 0.9097 - val_loss: 0.6716 - val_acc: 0.7288\n",
      "Epoch 9\n",
      "1s - loss: 0.2072 - acc: 0.9255 - val_loss: 0.7859 - val_acc: 0.7124\n",
      "Epoch 10\n",
      "1s - loss: 0.1746 - acc: 0.9397 - val_loss: 0.6939 - val_acc: 0.7272\n",
      "Epoch 11\n",
      "1s - loss: 0.1489 - acc: 0.9541 - val_loss: 0.7966 - val_acc: 0.7171\n",
      "Epoch 12\n",
      "1s - loss: 0.1255 - acc: 0.9668 - val_loss: 0.8985 - val_acc: 0.7167\n",
      "Epoch 13\n",
      "1s - loss: 0.1038 - acc: 0.9737 - val_loss: 0.9635 - val_acc: 0.7182\n",
      "Epoch 14\n",
      "1s - loss: 0.0871 - acc: 0.9802 - val_loss: 0.9540 - val_acc: 0.7198\n",
      "Epoch 15\n",
      "1s - loss: 0.0712 - acc: 0.9881 - val_loss: 1.0319 - val_acc: 0.7159\n",
      "Epoch 16\n",
      "1s - loss: 0.0625 - acc: 0.9901 - val_loss: 1.1361 - val_acc: 0.7136\n",
      "Epoch 17\n",
      "1s - loss: 0.0538 - acc: 0.9915 - val_loss: 1.2000 - val_acc: 0.7124\n",
      "Epoch 18\n",
      "1s - loss: 0.0493 - acc: 0.9921 - val_loss: 1.2224 - val_acc: 0.7159\n",
      "Epoch 19\n",
      "1s - loss: 0.0463 - acc: 0.9940 - val_loss: 1.2798 - val_acc: 0.7159\n",
      "[1.2955618863702658, 0.69995311767463664]\n",
      "2133/2133 [==============================] - 0s     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.69995311767463664"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## train model under an sklearn interface\n",
    "## model snapshot callback\n",
    "#save_model = ModelCheckpoint(\"data/tmp/keras_mlp.h5\")\n",
    "model.fit(train_X, train_y, batch_size=100, nb_epoch=20, \n",
    "          show_accuracy=True, verbose=2, validation_split=0.3)\n",
    "\n",
    "## evaluate on test data\n",
    "print model.evaluate(test_X, test_y, show_accuracy=True, verbose=0)\n",
    "np.mean(model.predict_classes(test_X) == test_y.argmax(axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
